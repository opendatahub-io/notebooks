{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df03ef8f-cfd8-42d6-8d37-28c92ecb63b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "from unittest import mock\n",
    "import pandas as pd\n",
    "import trustyai as trustyai\n",
    "from platform import python_version\n",
    "from trustyai.metrics.fairness.group import statistical_parity_difference\n",
    "from trustyai.model import output\n",
    "from pandas.testing import assert_frame_equal\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n",
    "from scipy import special\n",
    "from scipy import integrate\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import kafka\n",
    "from kafka import KafkaConsumer, KafkaProducer, TopicPartition\n",
    "from kafka.producer.buffer import SimpleBufferPool\n",
    "from kafka import KafkaConsumer\n",
    "from kafka.errors import KafkaConfigurationError\n",
    "import boto3\n",
    "import jupyterlab as jp\n",
    "import nbdime\n",
    "import nbgitpuller\n",
    "\n",
    "def get_major_minor(s):\n",
    "    return '.'.join(s.split('.')[:2])\n",
    "\n",
    "class TestPythonVersion(unittest.TestCase):\n",
    "    def test_version(self):\n",
    "        expected_major_minor = '3.9'\n",
    "        actual_major_minor = get_major_minor(python_version())\n",
    "        self.assertEqual(actual_major_minor, expected_major_minor, \"incorrect version\")\n",
    "\n",
    "class TestDependenciesVersions(unittest.TestCase):\n",
    "    def test_jupyter_version(self):\n",
    "        expected_major_minor = '3.6'\n",
    "        actual_major_minor = get_major_minor(jp.__version__)\n",
    "        self.assertEqual(actual_major_minor, expected_major_minor, \"incorrect version\")\n",
    "\n",
    "    def test_nbgitpuller_version(self):\n",
    "        expected_major_minor = '1.2'\n",
    "        actual_major_minor = get_major_minor(nbgitpuller.__version__)\n",
    "        self.assertEqual(actual_major_minor, expected_major_minor, \"incorrect version\")\n",
    "\n",
    "    def test_nbdime_version(self):\n",
    "        expected_major_minor = '3.2'\n",
    "        actual_major_minor = get_major_minor(nbdime.__version__)\n",
    "        self.assertEqual(actual_major_minor, expected_major_minor, \"incorrect version\")\n",
    "\n",
    "class TestPandas(unittest.TestCase):\n",
    "    def test_version(self):\n",
    "        expected_major_minor = '1.5'\n",
    "        actual_major_minor = get_major_minor(pd.__version__)\n",
    "        self.assertEqual(actual_major_minor, expected_major_minor, \"incorrect version\")\n",
    "\n",
    "    def test_dataframe_creation(self):\n",
    "        sample_df = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n",
    "        self.assertIsInstance(sample_df, pd.core.frame.DataFrame)\n",
    "\n",
    "    def test_equal_dataframes(self):\n",
    "        df1 = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n",
    "        df2 = pd.DataFrame({'a': [1, 2], 'b': [3.0, 4.0]})\n",
    "        self.assertIsNone(assert_frame_equal(df1, df2, check_dtype=False), \"Dataframes provided are unequal\")\n",
    "\n",
    "    def test_unequal_dataframes(self):\n",
    "        df1 = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n",
    "        df2 = pd.DataFrame({'a': [1, 2], 'b': [3.0, 5.0]})\n",
    "        with self.assertRaises(AssertionError):\n",
    "            assert_frame_equal(df1, df2, check_dtype=False)\n",
    "\n",
    "    def test_dataframe_shape(self):\n",
    "        random_data = {\n",
    "            'apples': [3, 2, 0, 1], \n",
    "            'oranges': [0, 3, 7, 2]\n",
    "        }\n",
    "        sample_df = pd.DataFrame(random_data)\n",
    "        self.assertEqual(sample_df.shape, (4,2))\n",
    "\n",
    "    def test_index_out_of_bounds(self):\n",
    "        random_data = {\n",
    "            'apples': [3, 2, 0, 1], \n",
    "            'oranges': [0, 3, 7, 2]\n",
    "        }\n",
    "        sample_df = pd.DataFrame(random_data)\n",
    "        with self.assertRaises(IndexError):\n",
    "            print(sample_df.iat[0,3])\n",
    "\n",
    "    def test_sampling(self):\n",
    "        random_data = {\n",
    "            'apples': [3, 2, 0, 1], \n",
    "            'oranges': [0, 3, 7, 2]\n",
    "        }\n",
    "        sample_df = pd.DataFrame(random_data)\n",
    "        half_sampled_df = sample_df.sample(frac = 0.5)\n",
    "        self.assertEqual(len(half_sampled_df), 2)\n",
    "\n",
    "    def test_drop(self):\n",
    "        random_data = {\n",
    "            'apples': [3, 2, 0, 1], \n",
    "            'oranges': [0, 3, 7, 2]\n",
    "        }\n",
    "        sample_df = pd.DataFrame(random_data)\n",
    "        self.assertEqual(sample_df.drop(columns=['apples']).shape, (4, 1))\n",
    "\n",
    "class TestNumpy(unittest.TestCase):\n",
    "    def test_version(self):\n",
    "        expected_major_minor = '1.24'\n",
    "        actual_major_minor = get_major_minor(np.__version__)\n",
    "        self.assertEqual(actual_major_minor, expected_major_minor, \"incorrect version\")\n",
    "\n",
    "    def test_array_creation(self):\n",
    "        arr = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "        self.assertIsInstance(arr, np.ndarray)\n",
    "        \n",
    "    def test_array_opeartions(self):\n",
    "        arr = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "        self.assertEqual(arr.sum(), 45)\n",
    "        self.assertEqual(len(arr), 9)\n",
    "        self.assertEqual(arr.max(), 9)\n",
    "        self.assertEqual(arr.min(), 1)\n",
    "\n",
    "    def test_array_statistical_functions(self):\n",
    "        arr = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "        self.assertEqual(np.median(arr), 5)\n",
    "        self.assertEqual(np.mean(arr), 5)\n",
    "        self.assertEqual(np.std(arr), 2.581988897471611)\n",
    "\n",
    "class TestScipy(unittest.TestCase):\n",
    "    def test_version(self):\n",
    "        expected_major_minor = '1.12'\n",
    "        actual_major_minor = get_major_minor(scipy.__version__)\n",
    "        self.assertEqual(actual_major_minor, expected_major_minor, \"incorrect version\")\n",
    "\n",
    "    def test_scipy_special(self):\n",
    "        self.assertEqual(special.exp10(3), 1000.0)\n",
    "        self.assertEqual(special.exp2(10), 1024.0)\n",
    "        self.assertEqual(special.sindg(90), 1)\n",
    "        self.assertEqual(special.cosdg(0), 1)\n",
    "\n",
    "    def test_scipy_integrate(self):\n",
    "        a= lambda x:special.exp10(x)\n",
    "        b = integrate.quad(a, 0, 1)\n",
    "        self.assertEqual(b, (3.9086503371292665, 4.3394735994897923e-14))\n",
    "\n",
    "class TestSKLearn(unittest.TestCase):\n",
    "    def test_version(self):\n",
    "        expected_major_minor = '1.4'\n",
    "        actual_major_minor = get_major_minor(sklearn.__version__)\n",
    "        self.assertEqual(actual_major_minor, expected_major_minor, \"incorrect version\")\n",
    "        \n",
    "    def test_sklearn_dataset(self):\n",
    "        data_set = datasets.load_iris()\n",
    "        self.assertIsInstance(data_set, sklearn.utils._bunch.Bunch)\n",
    "\n",
    "    def test_sklearn_train_test_split(self):\n",
    "        my_iris = datasets.load_iris()\n",
    "        X = my_iris.data\n",
    "        Y = my_iris.target\n",
    "\n",
    "        X_traindata, X_testdata, Y_traindata, Y_testdata = train_test_split(\n",
    "            X, Y, test_size = 0.3, random_state = 1)\n",
    "        \n",
    "        self.assertEqual(X_traindata.shape, (105, 4))\n",
    "        self.assertEqual(X_testdata.shape, (45, 4))\n",
    "        self.assertEqual(Y_traindata.shape, (105,))\n",
    "        self.assertEqual(Y_testdata.shape, (45,))\n",
    "\n",
    "class TestMatplotlib(unittest.TestCase):\n",
    "\n",
    "    def test_version(self):\n",
    "        expected_major_minor = '3.6'\n",
    "        actual_major_minor = get_major_minor(matplotlib.__version__)\n",
    "        self.assertEqual(actual_major_minor, expected_major_minor, \"incorrect version\")\n",
    "\n",
    "    def test_matplotlib_figure_creation(self):\n",
    "        self.assertIsInstance(plt.figure(figsize=(8,5)), matplotlib.figure.Figure)\n",
    "\n",
    "class TestKafkaPython(unittest.TestCase):\n",
    "\n",
    "    def test_version(self):\n",
    "        expected_major_minor = '2.0'\n",
    "        actual_major_minor = get_major_minor(kafka.__version__)\n",
    "        self.assertEqual(actual_major_minor, expected_major_minor, \"incorrect version\")\n",
    "\n",
    "    def test_buffer_pool(self):\n",
    "        pool = SimpleBufferPool(1000, 1000)\n",
    "    \n",
    "        buf1 = pool.allocate(1000, 1000)\n",
    "        message = ''.join(map(str, range(100)))\n",
    "        buf1.write(message.encode('utf-8'))\n",
    "        pool.deallocate(buf1)\n",
    "    \n",
    "        buf2 = pool.allocate(1000, 1000)\n",
    "        self.assertEqual(buf2.read(), b'')\n",
    "\n",
    "    def test_session_timeout_larger_than_request_timeout_raises(self):\n",
    "        with self.assertRaises(KafkaConfigurationError):\n",
    "            KafkaConsumer(bootstrap_servers='localhost:9092', api_version=(0, 9), group_id='foo', session_timeout_ms=50000, request_timeout_ms=40000)\n",
    "\n",
    "class TestBoto3(unittest.TestCase):\n",
    "\n",
    "    def test_version(self):\n",
    "        expected_major_minor = '1.34'\n",
    "        actual_major_minor = get_major_minor(boto3.__version__)\n",
    "        self.assertEqual(actual_major_minor, expected_major_minor, \"incorrect version\")\n",
    "\n",
    "    def setUp(self):\n",
    "        self.session_patch = mock.patch('boto3.Session', autospec=True)\n",
    "        self.Session = self.session_patch.start()\n",
    "\n",
    "    def tearDown(self):\n",
    "        boto3.DEFAULT_SESSION = None\n",
    "        self.session_patch.stop()\n",
    "\n",
    "    def test_create_default_session(self):\n",
    "        session = self.Session.return_value\n",
    "\n",
    "        boto3.setup_default_session()\n",
    "\n",
    "        self.assertEqual(boto3.DEFAULT_SESSION, session)\n",
    "\n",
    "class TestTrustyaiNotebook(unittest.TestCase):\n",
    "\n",
    "    def test_trustyai_version(self): \n",
    "        expected_major_minor = '0.6' # Set the expected version (x.y) \n",
    "        actual_major_minor = get_major_minor(trustyai.__version__)\n",
    "        self.assertEqual(actual_major_minor, expected_major_minor, \"incorrect version\")\n",
    "\n",
    "    def test_fairnessmetrics(self):\n",
    "        url_unbiased = \"https://raw.githubusercontent.com/opendatahub-io/notebooks/main/jupyter/trustyai/ubi9-python-3.9/test/income-unbiased.csv\"\n",
    "        nobias = pd.read_csv(url_unbiased, index_col=False)\n",
    "        \n",
    "        nobias = pd.read_csv(url_unbiased, index_col=False)\n",
    "        nobias.groupby(['gender', 'income'])['income'].count()\n",
    "        nobias.groupby(['gender', 'income'])['income'].count().unstack().plot.bar()\n",
    "        \n",
    "        nobias_privileged = nobias[nobias.gender == 1]\n",
    "        nobias_unprivileged = nobias[nobias.gender == 0]\n",
    "        favorable = output(\"income\", dtype=\"number\", value=1)\n",
    "        score = statistical_parity_difference(privileged=nobias_privileged,\n",
    "                                              unprivileged=nobias_unprivileged,\n",
    "                                              favorable=[favorable])\n",
    "        self.assertTrue(score >= 0.0036255104824703954)  \n",
    "        print(\"On the test_fairness_metrics test case the statistical_parity_difference score for this dataset is between the threshold [-0.1,0.1], which classifies the model as reasonably fair.\")\n",
    "        \n",
    "    def test_datafairness(self):\n",
    "        url_biased = \"https://raw.githubusercontent.com/opendatahub-io/notebooks/main/jupyter/trustyai/ubi9-python-3.9/test/income-biased.csv\"\n",
    "        bias = pd.read_csv(url_biased, index_col=False)\n",
    "        \n",
    "        # Perform the data manipulations \n",
    "        grouped_counts = bias.groupby(['gender', 'income'])['income'].count()\n",
    "        unstacked_counts = bias.groupby(['gender', 'income'])['income'].count().unstack()\n",
    "        unstacked_counts.plot.bar()\n",
    "\n",
    "        bias_privileged = bias[bias.gender == 1]\n",
    "        bias_unprivileged = bias[bias.gender == 0]\n",
    "        favorable = output(\"income\", dtype=\"number\", value=1)\n",
    "        score = statistical_parity_difference(privileged=bias_privileged,\n",
    "                                              unprivileged=bias_unprivileged,\n",
    "                                              favorable=[favorable])\n",
    "        self.assertTrue(score <= -0.15670061634672994)\n",
    "        print(\"On the test_bias_metrics test case the statistical_parity_difference score for this dataset, as expected, is outside the threshold [-0.1,0.1], which classifies the model as unfair.\")\n",
    "    \n",
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df03ef8f-cfd8-42d6-8d37-28c92ecb63b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "import unittest\n",
    "from unittest import mock\n",
    "import pandas as pd\n",
    "import trustyai as trustyai\n",
    "from platform import python_version\n",
    "from trustyai.metrics.fairness.group import statistical_parity_difference\n",
    "from trustyai.model import output\n",
    "from pandas.testing import assert_frame_equal\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n",
    "from scipy import special\n",
    "from scipy import integrate\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import kafka\n",
    "from kafka import KafkaConsumer, KafkaProducer, TopicPartition\n",
    "from kafka.producer.buffer import SimpleBufferPool\n",
    "from kafka import KafkaConsumer\n",
    "from kafka.errors import KafkaConfigurationError\n",
    "import boto3\n",
    "import jupyterlab as jp\n",
    "import nbdime\n",
    "import nbgitpuller\n",
    "\n",
    "def get_major_minor(s):\n",
    "    return '.'.join(s.split('.')[:2])\n",
    "\n",
    "def load_expected_versions() -> dict:\n",
    "    lock_file = Path('./expected_versions.json')\n",
    "    data = {}\n",
    "\n",
    "    with open(lock_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data    \n",
    "\n",
    "def get_expected_version(dependency_name: str) -> str:\n",
    "    raw_value = expected_versions.get(dependency_name)\n",
    "    raw_version = re.sub(r'^\\D+', '', raw_value)\n",
    "    return get_major_minor(raw_version) \n",
    "\n",
    "class TestPythonVersion(unittest.TestCase):\n",
    "    def test_version(self):\n",
    "        expected_major_minor = get_expected_version('Python')\n",
    "        actual_major_minor = get_major_minor(python_version())\n",
    "        self.assertEqual(actual_major_minor, expected_major_minor, \"incorrect version\")\n",
    "\n",
    "class TestTrustyaiNotebook(unittest.TestCase):\n",
    "\n",
    "    def test_trustyai_version(self):\n",
    "        expected_major_minor = get_expected_version('TrustyAI')\n",
    "        actual_major_minor = get_major_minor(trustyai.__version__)\n",
    "        self.assertEqual(actual_major_minor, expected_major_minor, \"incorrect version\")\n",
    "\n",
    "    def test_fairnessmetrics(self):\n",
    "        url_unbiased = \"https://raw.githubusercontent.com/opendatahub-io/notebooks/main/jupyter/trustyai/ubi9-python-3.11/test/income-unbiased.csv\"\n",
    "        nobias = pd.read_csv(url_unbiased, index_col=False)\n",
    "\n",
    "        nobias = pd.read_csv(url_unbiased, index_col=False)\n",
    "        nobias.groupby(['gender', 'income'])['income'].count()\n",
    "        nobias.groupby(['gender', 'income'])['income'].count().unstack().plot.bar()\n",
    "\n",
    "        nobias_privileged = nobias[nobias.gender == 1]\n",
    "        nobias_unprivileged = nobias[nobias.gender == 0]\n",
    "        favorable = output(\"income\", dtype=\"number\", value=1)\n",
    "        score = statistical_parity_difference(privileged=nobias_privileged,\n",
    "                                              unprivileged=nobias_unprivileged,\n",
    "                                              favorable=[favorable])\n",
    "        self.assertTrue(score >= 0.0036255104824703954)\n",
    "        print(\"On the test_fairness_metrics test case the statistical_parity_difference score for this dataset is between the threshold [-0.1,0.1], which classifies the model as reasonably fair.\")\n",
    "\n",
    "    def test_datafairness(self):\n",
    "        url_biased = \"https://raw.githubusercontent.com/opendatahub-io/notebooks/main/jupyter/trustyai/ubi9-python-3.11/test/income-biased.csv\"\n",
    "        bias = pd.read_csv(url_biased, index_col=False)\n",
    "\n",
    "        # Perform the data manipulations\n",
    "        grouped_counts = bias.groupby(['gender', 'income'])['income'].count()\n",
    "        unstacked_counts = bias.groupby(['gender', 'income'])['income'].count().unstack()\n",
    "        unstacked_counts.plot.bar()\n",
    "\n",
    "        bias_privileged = bias[bias.gender == 1]\n",
    "        bias_unprivileged = bias[bias.gender == 0]\n",
    "        favorable = output(\"income\", dtype=\"number\", value=1)\n",
    "        score = statistical_parity_difference(privileged=bias_privileged,\n",
    "                                              unprivileged=bias_unprivileged,\n",
    "                                              favorable=[favorable])\n",
    "        self.assertTrue(score <= -0.15670061634672994)\n",
    "        print(\"On the test_bias_metrics test case the statistical_parity_difference score for this dataset, as expected, is outside the threshold [-0.1,0.1], which classifies the model as unfair.\")\n",
    "\n",
    "expected_versions = load_expected_versions()\n",
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

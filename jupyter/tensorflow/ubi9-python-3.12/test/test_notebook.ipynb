{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ae2840-42b4-49a9-92da-250e03bdb13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "import unittest\n",
    "import tensorflow as tf\n",
    "import tensorboard\n",
    "import tf2onnx\n",
    "import os\n",
    "import ssl\n",
    "from platform import python_version\n",
    "\n",
    "def get_major_minor(s):\n",
    "    return '.'.join(s.split('.')[:2])\n",
    "\n",
    "def load_expected_versions() -> dict:\n",
    "    lock_file = Path('./expected_versions.json')\n",
    "    if not lock_file.exists():\n",
    "        raise FileNotFoundError(\"expected_versions.json not found.\")\n",
    "    with open(lock_file, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def get_expected_version(dependency_name: str) -> str:\n",
    "    raw_value = expected_versions.get(dependency_name)\n",
    "    raw_version = re.sub(r'^\\D+', '', raw_value)\n",
    "    return get_major_minor(raw_version)\n",
    "\n",
    "class TestTensorflowNotebook(unittest.TestCase):\n",
    "\n",
    "    def test_python_version(self):\n",
    "        expected_major_minor = get_expected_version('Python')\n",
    "        actual_major_minor = '.'.join(python_version().split('.')[:2])\n",
    "        self.assertEqual(actual_major_minor, expected_major_minor, \"Incorrect Python version\")\n",
    "\n",
    "    def test_tensorflow_version(self):\n",
    "        expected_major_minor = get_expected_version('TensorFlow')\n",
    "        actual_major_minor = '.'.join(tf.__version__.split('.')[:2])\n",
    "        self.assertEqual(actual_major_minor, expected_major_minor, \"Incorrect TensorFlow version\")\n",
    "\n",
    "    def test_tf2onnx_conversion(self):\n",
    "        # Workaround for known issues with tf2onnx + tf.keras\n",
    "        inputs = tf.keras.Input(shape=(10,))\n",
    "        flatten_layer = tf.keras.layers.Flatten()(inputs)\n",
    "        outputs = tf.keras.layers.Dense(1)(flatten_layer)\n",
    "        model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "        onnx_model = tf2onnx.convert.from_keras(model, input_signature=[tf.TensorSpec(model.inputs[0].shape)])\n",
    "        self.assertTrue(onnx_model is not None)\n",
    "\n",
    "    def test_mnist_model(self):\n",
    "        mnist = tf.keras.datasets.mnist\n",
    "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "        x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(10)\n",
    "        ])\n",
    "        predictions = model(x_train[:1]).numpy()\n",
    "        tf.nn.softmax(predictions).numpy()\n",
    "        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "        loss_fn(y_train[:1], predictions).numpy()\n",
    "        model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "        model.fit(x_train, y_train, epochs=5)\n",
    "        model.evaluate(x_test, y_test, verbose=2)\n",
    "        probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
    "        probability_model(x_test[:5])\n",
    "\n",
    "    def test_tensorboard(self):\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(10, input_shape=(5,), activation='relu'),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        x_train = tf.random.normal((100, 5))\n",
    "        y_train = tf.random.normal((100, 1))\n",
    "        log_dir = './logs'\n",
    "        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "        model.fit(x_train, y_train, epochs=2, callbacks=[tensorboard_callback])\n",
    "\n",
    "class TestSecurity(unittest.TestCase):\n",
    "\n",
    "    def test_jupyter_password_env(self):\n",
    "        self.assertIn(\"JUPYTER_PASSWORD\", os.environ, \"Missing JUPYTER_PASSWORD env variable for login protection\")\n",
    "\n",
    "    def test_ssl_files_exist(self):\n",
    "        cert_file = os.environ.get(\"JUPYTER_SSL_CERT\", \"/etc/jupyter/ssl/cert.pem\")\n",
    "        key_file = os.environ.get(\"JUPYTER_SSL_KEY\", \"/etc/jupyter/ssl/key.pem\")\n",
    "        self.assertTrue(os.path.exists(cert_file), f\"SSL cert not found: {cert_file}\")\n",
    "        self.assertTrue(os.path.exists(key_file), f\"SSL key not found: {key_file}\")\n",
    "\n",
    "    def test_ssl_certificate_validity(self):\n",
    "        cert_file = os.environ.get(\"JUPYTER_SSL_CERT\", \"/etc/jupyter/ssl/cert.pem\")\n",
    "        try:\n",
    "            context = ssl.create_default_context()\n",
    "            context.load_cert_chain(certfile=cert_file)\n",
    "        except Exception as e:\n",
    "            self.fail(f\"Invalid SSL certificate: {e}\")\n",
    "\n",
    "    def test_host_not_public(self):\n",
    "        host = os.environ.get(\"JUPYTER_HOST\", \"localhost\")\n",
    "        self.assertIn(host, [\"localhost\", \"127.0.0.1\"], f\"Jupyter host is publicly exposed: {host}\")\n",
    "\n",
    "expected_versions = load_expected_versions()\n",
    "\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestTensorflowNotebook)\n",
    "unittest.TextTestRunner().run(suite)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

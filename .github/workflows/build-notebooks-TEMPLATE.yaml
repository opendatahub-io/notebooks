# inspired by
# https://github.com/thesuperzapper/kubeflow/blob/master/.github/workflows/example_notebook_servers_publish_TEMPLATE.yaml
---
name: Build & Publish Notebook Servers (TEMPLATE)
"on":
  workflow_call:
    inputs:
      # https://docs.github.com/en/actions/learn-github-actions/variables#default-environment-variables
      # https://docs.github.com/en/actions/learn-github-actions/contexts
      target:
        required: true
        description: "make target to build"
        type: string
      github:
        required: true
        description: "top workflow's `github`"
        type: string

jobs:
  build:
    runs-on: ubuntu-22.04
    env:
      # GitHub image registry used for storing $(CONTAINER_ENGINE)'s cache
      CACHE: "ghcr.io/${{ github.repository }}/workbench-images/build-cache"
      TRIVY_VERSION: 0.57.1
      # Targets (and their folder) that should be scanned using FS instead of IMAGE scan due to resource constraints
      TRIVY_SCAN_FS_JSON: '{}'

    steps:

      - uses: actions/checkout@v4

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Free up additional disk space
        # https://docs.github.com/en/actions/learn-github-actions/expressions
        if: "${{ contains(inputs.target, 'rocm') || contains(inputs.target, 'cuda') || contains(inputs.target, 'intel') ||
         contains(inputs.target, 'pytorch') || contains(inputs.target, 'tensorflow') }}"
        run: |
          set -x

          df -h

          sudo apt-get update
          sudo apt-get remove -y '^dotnet-.*'
          sudo apt-get remove -y '^llvm-.*'
          sudo apt-get remove -y 'php.*'
          sudo apt-get remove -y '^mongodb-.*'
          sudo apt-get autoremove -y
          sudo apt-get clean
          sudo rm -rf /usr/local/.ghcup &
          sudo rm -rf /usr/local/lib/android &
          sudo rm -rf /usr/local/share/boost &
          sudo rm -rf /usr/local/lib/node_modules &
          sudo rm -rf /usr/share/dotnet &
          sudo rm -rf /opt/ghc &
          sudo rm -rf /opt/hostedtoolcache/CodeQL &

          sudo docker image prune --all --force &

          wait

          df -h

      - name: Mount lvm overlay for podman builds
        run: |
          df -h
          free -h

          bash ./ci/cached-builds/gha_lvm_overlay.sh

          df -h
          free -h

      # https://github.com/containers/buildah/issues/2521#issuecomment-884779112
      - name: Workaround https://github.com/containers/podman/issues/22152#issuecomment-2027705598
        run: sudo apt-get -qq remove podman crun

      - uses: actions/cache@v4
        id: cached-linuxbrew
        with:
          path: /home/linuxbrew/.linuxbrew
          key: linuxbrew

      - name: Install podman
        if: steps.cached-linuxbrew.outputs.cache-hit != 'true'
        run: |
          /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
          /home/linuxbrew/.linuxbrew/bin/brew install podman

      - name: Add linuxbrew to PATH
        run: echo "/home/linuxbrew/.linuxbrew/bin/" >> $GITHUB_PATH

      - name: Configure Podman
        run: |
          set -x
          mkdir -p $HOME/.config/containers/
          cp ci/cached-builds/containers.conf $HOME/.config/containers/containers.conf
          cp ci/cached-builds/storage.conf $HOME/.config/containers/storage.conf

          # should at least reset storage when touching storage.conf
          podman system reset --force
          mkdir -p $HOME/.local/share/containers/storage/tmp

          # start systemd user service
          # since `brew services start podman` is buggy, let's do our own brew-compatible service
          mkdir -p "${HOME}/.config/systemd/user/"
          cp ci/cached-builds/homebrew.podman.service "${HOME}/.config/systemd/user/homebrew.podman.service"
          systemctl --user daemon-reload
          systemctl --user start homebrew.podman.service
          echo "PODMAN_SOCK=/run/user/${UID}/podman/podman.sock" >> $GITHUB_ENV

      - name: "pull_request|schedule: resolve target if Trivy scan should run"
        id: resolve-target
        if: ${{ fromJson(inputs.github).event_name == 'pull_request' || fromJson(inputs.github).event_name == 'schedule' }}
        env:
          EVENT_NAME: ${{ fromJson(inputs.github).event_name }}
          HAS_TRIVY_LABEL: ${{ contains(fromJson(inputs.github).event.pull_request.labels.*.name, 'trivy-scan') }}
          FS_SCAN_FOLDER: ${{ fromJson(env.TRIVY_SCAN_FS_JSON)[inputs.target] }}
        run: |
          if [[ "$EVENT_NAME" == "pull_request" && "$HAS_TRIVY_LABEL" == "true" ]]; then
            if [[ -n "$FS_SCAN_FOLDER" ]]; then
              TARGET="$FS_SCAN_FOLDER"
              TYPE="fs"
            else
              TARGET="ghcr.io/${{ github.repository }}/workbench-images:${{ inputs.target }}-${{ github.sha }}"
              TYPE="image"
            fi
          elif [[ "$EVENT_NAME" == "schedule" ]]; then
            if [[ -n "$FS_SCAN_FOLDER" ]]; then
              TARGET="$FS_SCAN_FOLDER"
              TYPE="fs"
            else
              TARGET="ghcr.io/${{ github.repository }}/workbench-images:${{ inputs.target }}-${{ github.ref_name }}_${{ github.sha }}"
              TYPE="image"
            fi
          fi

          if [[ -n "$TARGET" ]]; then
            echo "target=$TARGET" >> $GITHUB_OUTPUT
            echo "type=$TYPE" >> $GITHUB_OUTPUT
            echo "Trivy scan will run on $TARGET ($TYPE)"
          else
            echo "Trivy scan won't run"
          fi

      # only one db can be downloaded in one call https://github.com/aquasecurity/trivy/issues/3616
      - name: Pre-pull Trivy vulnerabilities DB
        if: ${{ steps.resolve-target.outputs.target }}
        run: |
          mkdir trivy_db
          podman run --rm \
            --env PODMAN_SOCK \
            -v ${PWD}/trivy_db:/cache \
            docker.io/aquasec/trivy:$TRIVY_VERSION \
              --cache-dir /cache \
              image \
              --download-db-only
          podman run --rm \
            --env PODMAN_SOCK \
            -v ${PWD}/trivy_db:/cache \
            docker.io/aquasec/trivy:$TRIVY_VERSION \
              --cache-dir /cache \
              image \
              --download-java-db-only

      # https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows#push
      - name: "push|schedule: make ${{ inputs.target }}"
        run: |
          SANITIZED_REF_NAME=$(echo "${{ github.ref_name }}" | sed 's/[^a-zA-Z0-9._-]/_/g')
          export IMAGE_TAG="${SANITIZED_REF_NAME}_${{ github.sha }}"
          make ${{ inputs.target }}
        if: ${{ fromJson(inputs.github).event_name == 'push' || fromJson(inputs.github).event_name == 'schedule' }}
        env:
          IMAGE_REGISTRY: "ghcr.io/${{ github.repository }}/workbench-images"
          CONTAINER_BUILD_CACHE_ARGS: "--cache-from ${{ env.CACHE }} --cache-to ${{ env.CACHE }}"
          # dependent images were already built and pushed, so just let podman pull it
          BUILD_DEPENDENT_IMAGES: "no"

      # https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows#pull_request
      - name: "pull_request: make ${{ inputs.target }}"
        run: |
          make ${{ inputs.target }}
        if: "${{ fromJson(inputs.github).event_name == 'pull_request' }}"
        env:
          IMAGE_TAG: "${{ github.sha }}"
          IMAGE_REGISTRY: "ghcr.io/${{ github.repository }}/workbench-images"
          CONTAINER_BUILD_CACHE_ARGS: "--cache-from ${{ env.CACHE }}"
          # We don't have access to image registry, so disable pushing
          PUSH_IMAGES: "no"

      - name: "Show podman images information"
        run: podman images --digests

      - name: Run Trivy vulnerability scanner
        if: ${{ steps.resolve-target.outputs.target }}
        run: |
          REPORT_FOLDER=${{ github.workspace }}/report
          REPORT_FILE=trivy-report.md
          REPORT_TEMPLATE=trivy-markdown.tpl

          mkdir -p $REPORT_FOLDER
          cp ci/$REPORT_TEMPLATE $REPORT_FOLDER

          SCAN_TARGET=${{ steps.resolve-target.outputs.target }}
          SCAN_TYPE=${{ steps.resolve-target.outputs.type }}
          echo "Scanning $SCAN_TARGET ($SCAN_TYPE)"

          if [[ "$SCAN_TYPE" == "image" ]]; then
            SCAN_ARGS="--image-src podman --podman-host /var/run/podman/podman.sock"
            PODMAN_ARGS="-v ${PODMAN_SOCK}:/var/run/podman/podman.sock"
          elif [[ "$SCAN_TYPE" == "fs" ]]; then
            WORKSPACE_FOLDER="/workspace"
            SCAN_TARGET="$WORKSPACE_FOLDER/$SCAN_TARGET"
            PODMAN_ARGS="-v ${{ github.workspace }}:$WORKSPACE_FOLDER"
          fi

          # have trivy access podman socket,
          # https://github.com/aquasecurity/trivy/issues/580#issuecomment-666423279
          podman run --rm \
              $PODMAN_ARGS \
              -v ${REPORT_FOLDER}:/report \
              -v ${PWD}/trivy_db:/cache \
              docker.io/aquasec/trivy:$TRIVY_VERSION \
                --cache-dir /cache \
                $SCAN_TYPE \
                $SCAN_ARGS \
                --skip-db-update \
                --scanners vuln --ignore-unfixed \
                --exit-code 0 --timeout 30m \
                --format template --template "@/report/$REPORT_TEMPLATE" -o /report/$REPORT_FILE \
                $SCAN_TARGET

          cat $REPORT_FOLDER/$REPORT_FILE >> $GITHUB_STEP_SUMMARY

      # https://playwright.dev/docs/ci
      # https://playwright.dev/docs/docker
      # we leave little free disk space after we mount LVM for podman storage
      # not enough to install playwright; running playwright in podman uses the space we have
      - name: Run Playwright tests
        if: ${{ fromJson(inputs.github).event_name == 'pull_request' && contains(inputs.target, 'codeserver') }}
        # --ipc=host because Microsoft says so in Playwright docs
        # --net=host because testcontainers connects to the Reaper container's exposed port
        # we need to pass through the relevant environment variables
        #  DEBUG configures nodejs debuggers, sets different verbosity as needed
        #  CI=true is set on every CI nowadays
        #  PODMAN_SOCK should be mounted to /var/run/docker.sock, other likely mounting locations may not exist (mkdir -p)
        #  TEST_TARGET is the workbench image the test will run
        # --volume(s) let us access docker socket and not clobber host's node_modules
        run: |
          podman run \
            --interactive --rm \
            --ipc=host \
            --net=host \
            --env "CI=true" \
            --env "NPM_CONFIG_fund=false" \
            --env "DEBUG=testcontainers:*" \
            --env "PODMAN_SOCK=/var/run/docker.sock" \
            --env "TEST_TARGET" \
            --volume ${PODMAN_SOCK}:/var/run/docker.sock \
            --volume ${PWD}:/mnt \
            --volume /mnt/node_modules \
            mcr.microsoft.com/playwright:v1.48.1-noble \
            /bin/bash <<EOF
              set -Eeuxo pipefail
              cd /mnt
              npm install -g pnpm && pnpm install
              pnpm exec playwright test
              exit 0
          EOF
        working-directory: tests/browser
        env:
          TEST_TARGET: "ghcr.io/${{ github.repository }}/workbench-images:${{ inputs.target }}-${{ github.sha }}"
      - uses: actions/upload-artifact@v4
        if: ${{ !cancelled() && fromJson(inputs.github).event_name == 'pull_request' && contains(inputs.target, 'codeserver') }}
        with:
          name: "${{ inputs.target }}_playwright-report"
          path: tests/browser/playwright-report/
          retention-days: 30

      - run: df -h
        if: "${{ !cancelled() }}"

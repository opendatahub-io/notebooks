{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daefaeec-e3ea-4381-bb80-8c6160fc26e0",
   "metadata": {},
   "source": [
    "# PyTorch Test Notebook\n",
    "\n",
    "This notebook aims to provide a very basic testing perspective on Jupyter notebooks with PyTorch installed, in such way that it will execute properly the following PyTorch scripts:\n",
    "\n",
    "1. PyTorch quickstart for beginners\n",
    "2. PyTorch tests (basic operations on GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3fbdc6-fafb-48a7-bfdb-4bf8f00ea414",
   "metadata": {},
   "source": [
    "## 1. PyTorch quickstart for beginners\n",
    "This test aims to use the basic Getting Started tutorial on PyTorch website to check if this installation is working properly:\n",
    "\n",
    "- Working with data;\n",
    "- Creating Models;\n",
    "- Optimizing the Model Parameters;\n",
    "- Saving Models;\n",
    "- Loading Models;\n",
    "\n",
    "The expected output here is a set of the following objects:\n",
    "\n",
    "- Dataset download;\n",
    "- Dataloader objects;\n",
    "- Model object;\n",
    "- Training epochs;\n",
    "- Model prediction;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a84a9ec-f867-44aa-b078-61156f71e132",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26.4M/26.4M [00:02<00:00, 11.9MB/s]\n",
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 195kB/s]\n",
      "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.58MB/s]\n",
      "100%|██████████| 5.15k/5.15k [00:00<00:00, 15.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.310729  [   64/60000]\n",
      "loss: 2.293337  [ 6464/60000]\n",
      "loss: 2.271836  [12864/60000]\n",
      "loss: 2.256696  [19264/60000]\n",
      "loss: 2.253461  [25664/60000]\n",
      "loss: 2.219933  [32064/60000]\n",
      "loss: 2.227298  [38464/60000]\n",
      "loss: 2.192452  [44864/60000]\n",
      "loss: 2.189365  [51264/60000]\n",
      "loss: 2.152730  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 42.2%, Avg loss: 2.151557 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.167950  [   64/60000]\n",
      "loss: 2.160891  [ 6464/60000]\n",
      "loss: 2.096020  [12864/60000]\n",
      "loss: 2.096901  [19264/60000]\n",
      "loss: 2.065094  [25664/60000]\n",
      "loss: 1.999475  [32064/60000]\n",
      "loss: 2.019183  [38464/60000]\n",
      "loss: 1.946982  [44864/60000]\n",
      "loss: 1.943459  [51264/60000]\n",
      "loss: 1.857313  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 59.4%, Avg loss: 1.872370 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.915516  [   64/60000]\n",
      "loss: 1.884085  [ 6464/60000]\n",
      "loss: 1.763265  [12864/60000]\n",
      "loss: 1.780235  [19264/60000]\n",
      "loss: 1.691249  [25664/60000]\n",
      "loss: 1.647905  [32064/60000]\n",
      "loss: 1.651384  [38464/60000]\n",
      "loss: 1.569169  [44864/60000]\n",
      "loss: 1.586267  [51264/60000]\n",
      "loss: 1.466440  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 61.9%, Avg loss: 1.503834 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.575909  [   64/60000]\n",
      "loss: 1.539083  [ 6464/60000]\n",
      "loss: 1.392623  [12864/60000]\n",
      "loss: 1.445052  [19264/60000]\n",
      "loss: 1.343696  [25664/60000]\n",
      "loss: 1.342208  [32064/60000]\n",
      "loss: 1.348126  [38464/60000]\n",
      "loss: 1.282338  [44864/60000]\n",
      "loss: 1.318679  [51264/60000]\n",
      "loss: 1.208444  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 1.245264 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.322217  [   64/60000]\n",
      "loss: 1.300874  [ 6464/60000]\n",
      "loss: 1.139720  [12864/60000]\n",
      "loss: 1.229537  [19264/60000]\n",
      "loss: 1.120478  [25664/60000]\n",
      "loss: 1.143530  [32064/60000]\n",
      "loss: 1.162224  [38464/60000]\n",
      "loss: 1.104267  [44864/60000]\n",
      "loss: 1.149957  [51264/60000]\n",
      "loss: 1.055109  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.0%, Avg loss: 1.083780 \n",
      "\n",
      "Done!\n",
      "Saved PyTorch Model State to model.pth\n",
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "\n",
    "# 1. Working with data\n",
    "# ----------------------------------------------------------------------------------------------\n",
    "# PyTorch offers domain-specific libraries such as TorchText, TorchVision,\n",
    "# and TorchAudio, all of which include datasets. For this tutorial, we will\n",
    "# be using a TorchVision dataset.\n",
    "#\n",
    "# The torchvision.datasets module contains Dataset objects for many real-world\n",
    "# vision data like CIFAR, COCO (full list here). In this tutorial, we use the\n",
    "# FashionMNIST dataset. Every TorchVision Dataset includes two arguments:\n",
    "# transform and target_transform to modify the samples and labels respectively.\n",
    "\n",
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# We pass the Dataset as an argument to DataLoader. This wraps an iterable over our dataset, and supports automatic batching, sampling,\n",
    "# shuffling and multiprocess data loading. Here we define a batch size of 64, i.e. each element in the dataloader iterable will return\n",
    "# a batch of 64 features and labels.\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break\n",
    "\n",
    "\n",
    "# 2. Creating Models\n",
    "# ----------------------------------------------------------------------------------------------\n",
    "# To define a neural network in PyTorch, we create a class that inherits\n",
    "# from nn.Module. We define the layers of the network in the __init__ function\n",
    "# and specify how data will pass through the network in the forward function.\n",
    "# To accelerate operations in the neural network, we move it to the accelerator\n",
    "# such as CUDA, MPS, MTIA, or XPU. If the current accelerator is available,\n",
    "# we will use it. Otherwise, we use the CPU.\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n",
    "\n",
    "\n",
    "# 3. Optimizing the Model Parameters\n",
    "# ----------------------------------------------------------------------------------------------\n",
    "# To train a model, we need a loss function and an optimizer.\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "# In a single training loop, the model makes predictions on the training\n",
    "# dataset (fed to it in batches), and backpropagates the prediction error\n",
    "# to adjust the model’s parameters.\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "# We also check the model’s performance against the test dataset to ensure\n",
    "# it is learning.\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")\n",
    "\n",
    "# 4. Saving Models\n",
    "# ----------------------------------------------------------------------------------------------\n",
    "# A common way to save a model is to serialize the internal state dictionary\n",
    "# (containing the model parameters).\n",
    "\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")\n",
    "\n",
    "\n",
    "# 5. Loading Models\n",
    "# ----------------------------------------------------------------------------------------------\n",
    "# The process for loading a model includes re-creating the model structure and\n",
    "# loading the state dictionary into it.\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"model.pth\", weights_only=True))\n",
    "\n",
    "# This model can now be used to make predictions.\n",
    "\n",
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a0ed9e-7372-4b3b-b6c0-0d252ee88c01",
   "metadata": {},
   "source": [
    "## 2. PyTorch tests (basic operations on GPU)\n",
    "This test aims to try out the GPU basic commands, like `tensor`, `from_numpy`, `ones_like`, `rand_like` among some more commands, just to be sure that PyTorch is really running well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2e44f63-6c50-493b-9742-125e2f09073b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Tensor initialization\n",
      "\n",
      "----- Tensor initialization directly from data\n",
      "\n",
      "----- Tensor initialization from a NumPy array\n",
      "\n",
      "----- Tensor initialization from another tensor\n",
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.3678, 0.4588],\n",
      "        [0.7819, 0.7682]]) \n",
      "\n",
      "\n",
      "----- Tensor initialization with random or constant values\n",
      "Random Tensor: \n",
      " tensor([[0.8846, 0.9072, 0.9605],\n",
      "        [0.3528, 0.9535, 0.0923]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n",
      "===== Tensor attributes\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n",
      "\n",
      "===== Tensor operations\n",
      "\n",
      "----- Move the tensor to the GPU (if available)\n",
      "Device tensor is stored on: cuda:0\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "\n",
      "----- Joining tensors\n",
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n",
      "\n",
      "----- Multiplying tensors\n",
      "tensor.mul(tensor) \n",
      " tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor * tensor \n",
      " tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "tensor.matmul(tensor.T) \n",
      " tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]]) \n",
      "\n",
      "tensor @ tensor.T \n",
      " tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n",
      "\n",
      "----- In-place operations\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]])\n",
      "\n",
      "===== Bridge with NumPy\n",
      "\n",
      "----- Tensor to NumPy array\n",
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n",
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n",
      "\n",
      "----- NumPy array to Tensor\n",
      "t: tensor([3., 3., 3., 3., 3.])\n",
      "n: [3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Tensor Initialization\n",
    "# ------------------------------------------------------------\n",
    "# Tensors can be initialized in various ways. Take a look at the following\n",
    "# examples:\n",
    "print(\"\\n===== Tensor initialization\")\n",
    "\n",
    "# - Directly from data\n",
    "# Tensors can be created directly from data. The data type is automatically\n",
    "# inferred.\n",
    "print(\"\\n----- Tensor initialization directly from data\")\n",
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "\n",
    "# - From a NumPy array\n",
    "# Tensors can be created from NumPy arrays (and vice versa - see Bridge\n",
    "# with NumPy).\n",
    "print(\"\\n----- Tensor initialization from a NumPy array\")\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "\n",
    "# - From another tensor:\n",
    "# The new tensor retains the properties (shape, datatype) of the\n",
    "# argument tensor, unless explicitly overridden.\n",
    "print(\"\\n----- Tensor initialization from another tensor\")\n",
    "\n",
    "# retains the properties of x_data\n",
    "x_ones = torch.ones_like(x_data)\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "# overrides the datatype of x_data\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float)\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")\n",
    "\n",
    "# - With random or constant values:\n",
    "# shape is a tuple of tensor dimensions. In the functions below, it determines\n",
    "# the dimensionality of the output tensor.\n",
    "print(\"\\n----- Tensor initialization with random or constant values\")\n",
    "shape = (2, 3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")\n",
    "\n",
    "\n",
    "# Tensor Attributes\n",
    "# ------------------------------------------------------------\n",
    "# Tensor attributes describe their shape, datatype, and the device on which they are stored.\n",
    "\n",
    "print(\"\\n===== Tensor attributes\")\n",
    "\n",
    "tensor = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")\n",
    "\n",
    "\n",
    "# Tensor Operations\n",
    "# ------------------------------------------------------------\n",
    "# Over 100 tensor operations, including transposing, indexing, slicing,\n",
    "# mathematical operations, linear algebra, random sampling, and more are\n",
    "# comprehensively described here.\n",
    "#\n",
    "# Each of them can be run on the GPU (at typically higher speeds than\n",
    "# on a CPU).\n",
    "print(\"\\n===== Tensor operations\")\n",
    "\n",
    "# We move our tensor to the GPU if available\n",
    "print(\"\\n----- Move the tensor to the GPU (if available)\")\n",
    "if torch.cuda.is_available():\n",
    "  tensor = tensor.to('cuda')\n",
    "  print(f\"Device tensor is stored on: {tensor.device}\")\n",
    "\n",
    "\n",
    "# Standard numpy-like indexing and slicing:\n",
    "tensor = torch.ones(4, 4)\n",
    "tensor[:,1] = 0\n",
    "print(tensor)\n",
    "\n",
    "# Joining tensors You can use torch.cat to concatenate a sequence of tensors\n",
    "# along a given dimension. See also torch.stack, another tensor joining op\n",
    "# that is subtly different from torch.cat\n",
    "print(\"\\n----- Joining tensors\")\n",
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)\n",
    "\n",
    "# Multiplying tensors\n",
    "# This computes the element-wise product\n",
    "print(\"\\n----- Multiplying tensors\")\n",
    "\n",
    "print(f\"tensor.mul(tensor) \\n {tensor.mul(tensor)} \\n\")\n",
    "# Alternative syntax:\n",
    "print(f\"tensor * tensor \\n {tensor * tensor}\")\n",
    "\n",
    "# This computes the matrix multiplication between two tensors\n",
    "print(f\"tensor.matmul(tensor.T) \\n {tensor.matmul(tensor.T)} \\n\")\n",
    "# Alternative syntax:\n",
    "print(f\"tensor @ tensor.T \\n {tensor @ tensor.T}\")\n",
    "\n",
    "# In-place operations\n",
    "# Operations that have a _ suffix are in-place.\n",
    "# For example: x.copy_(y), x.t_(), will change x.\n",
    "print(\"\\n----- In-place operations\")\n",
    "print(tensor, \"\\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)\n",
    "\n",
    "\n",
    "# Bridge with NumPy\n",
    "# ------------------------------------------------------------\n",
    "# Tensors on the CPU and NumPy arrays can share their underlying\n",
    "# memory locations, and changing one will change the other.\n",
    "print(\"\\n===== Bridge with NumPy\")\n",
    "\n",
    "# Tensor to NumPy array\n",
    "print(\"\\n----- Tensor to NumPy array\")\n",
    "\n",
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")\n",
    "\n",
    "# A change in the tensor reflects in the NumPy array.\n",
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")\n",
    "\n",
    "# NumPy array to Tensor\n",
    "print(\"\\n----- NumPy array to Tensor\")\n",
    "\n",
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9749d97-cc7a-4ef0-afb4-f4df9b9b5ef2",
   "metadata": {},
   "source": [
    "For more information of the methods that will be tested here:\n",
    "- [torch.Tensor](https://docs.pytorch.org/docs/stable/tensors.html)<br/>\n",
    "  A `torch.Tensor` is a multi-dimensional matrix containing elements of a single data type\n",
    "\n",
    "- [torch.from_numpy](https://docs.pytorch.org/docs/stable/generated/torch.from_numpy.html)<br />\n",
    "  Creates a `Tensor` from a `numpy.ndarray`<br />\n",
    "  The returned tensor and `ndarray` share the same memory. Modifications to the tensor will be reflected in the `ndarray` and vice versa. The returned tensor is not resizable.\n",
    "\n",
    "- [torch.ones_like](https://docs.pytorch.org/docs/stable/generated/torch.ones_like.html)<br />\n",
    "  Returns a tensor filled with the scalar value 1, with the same size as `input`. `torch.ones_like(input)` is equivalent to `torch.ones(input.size(), dtype=input.dtype, layout=input.layout, device=input.device)`\n",
    "\n",
    "- [torch.rand_like](https://docs.pytorch.org/docs/stable/generated/torch.rand_like.html)<br />\n",
    "  Returns a tensor with the same size as `input` that is filled with random numbers from a uniform distribution on the interval [0, 1)[0,1). `torch.rand_like(input)` is equivalent to `torch.rand(input.size(), dtype=input.dtype, layout=input.layout, device=input.device)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f9058d-8cf1-4280-9f94-67d96e3bdb90",
   "metadata": {},
   "source": [
    "## 3. PyTorch GPU operations\n",
    "\n",
    "The following test will run some operations directly on the GPU to ensure that the Jupyter Notebook and GPUs are working properly together on this environment's setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca136162-8d59-4b04-883f-d226f7a89262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple GPU Tensor Operations Test\n",
      "========================================\n",
      "Detected GPU backend: AMD ROCm\n",
      "Target device: cuda\n",
      "Device name: AMD Instinct MI300X VF\n",
      "\n",
      "1. Creating tensors directly on GPU:\n",
      "   Tensor a device: cuda:0\n",
      "   Tensor b device: cuda:0\n",
      "   Tensor c device: cuda:0\n",
      "   Tensor a:\n",
      "tensor([[-0.7475,  1.6155,  1.0797, -1.9877],\n",
      "        [ 0.5451, -2.5021,  1.8317,  0.8946],\n",
      "        [ 0.4863, -0.1370,  1.2617,  1.4519]], device='cuda:0')\n",
      "\n",
      "2. Basic arithmetic operations (all on GPU):\n",
      "   Addition result device: cuda:0\n",
      "   Multiplication result device: cuda:0\n",
      "   Matrix mult result device: cuda:0\n",
      "   Matrix multiplication result shape: torch.Size([3, 3])\n",
      "\n",
      "3. Moving tensor from CPU to GPU:\n",
      "   Original tensor device: cpu\n",
      "   Moved tensor device: cuda:0\n",
      "\n",
      "4. Complex tensor operations on GPU:\n",
      "   Input x device: cuda:0\n",
      "   Input y device: cuda:0\n",
      "   Final result device: cuda:0\n",
      "   Final result shape: torch.Size([30])\n",
      "   Final result sample: tensor([0.0291, 0.0143, 0.0169, 0.0223, 0.0712], device='cuda:0')\n",
      "\n",
      "5. Neural network operations on GPU:\n",
      "   Model parameters device: cuda:0\n",
      "   Input data device: cuda:0\n",
      "   Model output device: cuda:0\n",
      "   Output shape: torch.Size([32, 5])\n",
      "\n",
      "6. Gradient computation on GPU:\n",
      "   Input x device: cuda:0\n",
      "   Target y device: cuda:0\n",
      "   Loss device: cuda:0\n",
      "   Gradient device: cuda:0\n",
      "   Gradient shape: torch.Size([5, 3])\n",
      "\n",
      "7. In-place operations on GPU:\n",
      "   Original tensor device: cuda:0\n",
      "   Original tensor:\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], device='cuda:0')\n",
      "   Modified tensor device: cuda:0\n",
      "   Modified tensor:\n",
      "tensor([[9., 9., 9.],\n",
      "        [9., 9., 9.],\n",
      "        [9., 9., 9.]], device='cuda:0')\n",
      "\n",
      "All operations completed successfully on GPU!\n",
      "All tensors maintained CUDA device throughout operations!\n",
      "Backend used: AMD ROCm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "print(\"Simple GPU Tensor Operations Test\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Detect available GPU device (CUDA or ROCm)\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    device_name = torch.cuda.get_device_name(0)\n",
    "\n",
    "    # Try to determine if we're using NVIDIA CUDA or AMD ROCm\n",
    "    if 'NVIDIA' in device_name or 'GeForce' in device_name or 'Tesla' in device_name or 'Quadro' in device_name:\n",
    "        backend = \"NVIDIA CUDA\"\n",
    "    elif 'AMD' in device_name or 'Radeon' in device_name or 'gfx' in device_name:\n",
    "        backend = \"AMD ROCm\"\n",
    "    else:\n",
    "        backend = \"CUDA-compatible GPU\"\n",
    "\n",
    "else:\n",
    "    raise RuntimeError(\"No GPU device available (neither CUDA nor ROCm detected)\")\n",
    "\n",
    "print(f\"Detected GPU backend: {backend}\")\n",
    "print(f\"Target device: {device}\")\n",
    "print(f\"Device name: {device_name}\")\n",
    "print()\n",
    "\n",
    "# 1. Create tensors directly on GPU\n",
    "print(\"1. Creating tensors directly on GPU:\")\n",
    "a = torch.randn(3, 4, device=device)\n",
    "b = torch.ones(3, 4, device=device)\n",
    "c = torch.zeros(2, 5, device=device)\n",
    "\n",
    "print(f\"   Tensor a device: {a.device}\")\n",
    "print(f\"   Tensor b device: {b.device}\")\n",
    "print(f\"   Tensor c device: {c.device}\")\n",
    "print(f\"   Tensor a:\\n{a}\")\n",
    "print()\n",
    "\n",
    "# 2. Basic arithmetic operations\n",
    "print(\"2. Basic arithmetic operations (all on GPU):\")\n",
    "result_add = a + b\n",
    "result_mul = a * b\n",
    "result_mm = torch.mm(a, b.T)  # Matrix multiplication\n",
    "\n",
    "print(f\"   Addition result device: {result_add.device}\")\n",
    "print(f\"   Multiplication result device: {result_mul.device}\")\n",
    "print(f\"   Matrix mult result device: {result_mm.device}\")\n",
    "print(f\"   Matrix multiplication result shape: {result_mm.shape}\")\n",
    "print()\n",
    "\n",
    "# 3. Create tensor on CPU and move to GPU\n",
    "print(\"3. Moving tensor from CPU to GPU:\")\n",
    "cpu_tensor = torch.randn(2, 3)\n",
    "print(f\"   Original tensor device: {cpu_tensor.device}\")\n",
    "\n",
    "gpu_tensor = cpu_tensor.to(device)\n",
    "print(f\"   Moved tensor device: {gpu_tensor.device}\")\n",
    "print()\n",
    "\n",
    "# 4. More complex operations\n",
    "print(\"4. Complex tensor operations on GPU:\")\n",
    "x = torch.randn(100, 50, device=device)\n",
    "y = torch.randn(50, 30, device=device)\n",
    "\n",
    "# Chain of operations\n",
    "result = torch.relu(torch.mm(x, y))\n",
    "result = torch.softmax(result, dim=1)\n",
    "mean_result = torch.mean(result, dim=0)\n",
    "\n",
    "print(f\"   Input x device: {x.device}\")\n",
    "print(f\"   Input y device: {y.device}\")\n",
    "print(f\"   Final result device: {mean_result.device}\")\n",
    "print(f\"   Final result shape: {mean_result.shape}\")\n",
    "print(f\"   Final result sample: {mean_result[:5]}\")\n",
    "print()\n",
    "\n",
    "# 5. Neural network operations\n",
    "print(\"5. Neural network operations on GPU:\")\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10, 20)\n",
    "        self.fc2 = nn.Linear(20, 5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create model and move to GPU\n",
    "model = SimpleNet().to(device)\n",
    "\n",
    "# Check if model parameters are on GPU\n",
    "print(f\"   Model parameters device: {next(model.parameters()).device}\")\n",
    "\n",
    "# Create input data on GPU\n",
    "input_data = torch.randn(32, 10, device=device)\n",
    "print(f\"   Input data device: {input_data.device}\")\n",
    "\n",
    "# Forward pass\n",
    "with torch.no_grad():\n",
    "    output = model(input_data)\n",
    "\n",
    "print(f\"   Model output device: {output.device}\")\n",
    "print(f\"   Output shape: {output.shape}\")\n",
    "print()\n",
    "\n",
    "# 6. Gradient computation on GPU\n",
    "print(\"6. Gradient computation on GPU:\")\n",
    "x = torch.randn(5, 3, device=device, requires_grad=True)\n",
    "y = torch.randn(5, 3, device=device)\n",
    "\n",
    "print(f\"   Input x device: {x.device}\")\n",
    "print(f\"   Target y device: {y.device}\")\n",
    "\n",
    "# Compute loss\n",
    "loss = torch.mean((x - y) ** 2)\n",
    "print(f\"   Loss device: {loss.device}\")\n",
    "\n",
    "# Backward pass\n",
    "loss.backward()\n",
    "print(f\"   Gradient device: {x.grad.device}\")\n",
    "print(f\"   Gradient shape: {x.grad.shape}\")\n",
    "print()\n",
    "\n",
    "# 7. In-place operations on GPU\n",
    "print(\"7. In-place operations on GPU:\")\n",
    "tensor = torch.ones(3, 3, device=device)\n",
    "print(f\"   Original tensor device: {tensor.device}\")\n",
    "print(f\"   Original tensor:\\n{tensor}\")\n",
    "\n",
    "# In-place operations\n",
    "tensor.add_(2.0)  # Add 2 to all elements\n",
    "tensor.mul_(3.0)  # Multiply all elements by 3\n",
    "\n",
    "print(f\"   Modified tensor device: {tensor.device}\")\n",
    "print(f\"   Modified tensor:\\n{tensor}\")\n",
    "print()\n",
    "\n",
    "print(\"All operations completed successfully on GPU!\")\n",
    "print(f\"All tensors maintained {device.upper()} device throughout operations!\")\n",
    "print(f\"Backend used: {backend}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e3a0d2-f22a-4a2f-900d-e87ea9bdc3f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

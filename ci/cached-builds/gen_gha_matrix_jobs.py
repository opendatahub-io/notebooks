import argparse
import itertools
import json
import logging
import os
import pathlib
import re
import string
import sys
import unittest
from typing import Iterable

import gha_pr_changed_files

"""Trivial Makefile parser that extracts target dependencies so that we can build each Dockerfile image target in its
own GitHub Actions job and handle dependencies between them.

The parsing is not able to handle general Makefiles, it only works with the Makefile in this project.
Use https://pypi.org/project/py-make/ or https://github.com/JetBrains/intellij-plugins/tree/master/makefile/grammars if you look for general parser."""

project_dir = pathlib.Path(__file__).parent.parent.parent.absolute()


def read_makefile_lines(lines: Iterable[str]) -> list[str]:
    """Processes line continuations lines and line comments
    Note that this does not handle escaped backslash and escaped hash, or hash inside literals, ..."""
    output = []
    current = ""
    for line in lines:
        # remove comment
        if (i := line.find("#")) != -1:
            line = line[:i]

        # line continuation
        if line.endswith("\\\n"):
            current += line[:-2]
        else:
            current += line[:-1]
            output.append(current)
            current = ""
    if current:
        output.append(current)
    return output


def extract_target_dependencies(lines: Iterable[str]) -> dict[str, list[str]]:
    tree = {}
    for line in lines:
        # not a target
        if line.startswith("\t"):
            continue
        # .PHONY targets and such
        if line.startswith("."):
            continue

        r = re.compile(r"""
        ^                     # match from beginning
        ([-A-Za-z0-9.]+)\s*:  # target name
        (?:\s*                # any number of spaces between dependent targets
            ([-A-Za-z0-9.]+)  #     dependent target name(s)
        )*                    # ...
        \s*$                  # any whitespace at the end of the line
        """, re.VERBOSE)
        if m := re.match(r, line):
            target, *deps = m.groups()
            if deps == [None]:
                deps = []
            tree[target] = deps
    return tree


def write_github_workflow_file(tree: dict[str, list[str]], path: pathlib.Path) -> None:
    jobs = {}

    # IDs may only contain alphanumeric characters, '_', and '-'. IDs must start with a letter or '_' and must be less than 100 characters.
    allowed_github_chars = string.ascii_letters + string.digits + "_-"

    for task, deps in tree.items():
        # in level 0, we only want base images, not other utility tasks
        if not deps:
            if not task.startswith("base-"):
                continue

        # we won't build rhel-based images because they need subscription
        if "rhel" in task:
            continue

        task_name = re.sub(r"[^-_0-9A-Za-z]", "_", task)
        deps_names = [re.sub(r"[^-_0-9A-Za-z]", "_", dep) for dep in deps]
        jobs[task_name] = {
            "needs": deps_names,
            "uses": "./.github/workflows/build-notebooks-TEMPLATE.yaml",
            "with": {
                "target": task,
                "github": "${{ toJSON(github) }}",
            },
            "secrets": "inherit",
        }

    workflow = {
        "name": "Build Notebooks",
        # https://docs.github.com/en/actions/security-guides/automatic-token-authentication#modifying-the-permissions-for-the-github_token
        "permissions": {
            "packages": "write",
        },
        "on": {
            "push": {},
            "workflow_dispatch": {},
        },
        "jobs": jobs,
    }

    with open(path, "wt") as f:
        print("---", file=f)
        print("# This file is autogenerated by", pathlib.Path(__file__).relative_to(project_dir), file=f)
        # every json file is a valid yaml file
        json.dump(workflow, f, sort_keys=False, indent=4)
        print(file=f)


def flatten(list_of_lists):
    return list(itertools.chain.from_iterable(list_of_lists))


def compute_leafs_in_dependency_tree(tree: dict[str, list[str]]) -> list[str]:
    key_set = set(tree.keys())
    value_set = set(flatten(tree.values()))
    return [key for key in key_set if key not in value_set]


def print_github_actions_pr_matrix(tree: dict[str, list[str]], leafs: list[str]) -> list[str]:
    """Outputs GitHub matrix definition Json
    """
    targets = []
    for leaf in leafs:
        # in level 0, we only want base images, not other utility tasks
        if not tree[leaf] and not leaf.startswith("base-"):
            continue

        # we won't build rhel-based images because they need a subscription
        if "rhel" in leaf:
            continue

        targets.append(leaf)

    matrix = {"target": targets}
    return [f"matrix={json.dumps(matrix, separators=(',', ':'))}",
            f"has_jobs={json.dumps(len(leafs) > 0, separators=(',', ':'))}"]


def main() -> None:
    logging.basicConfig(level=logging.DEBUG, stream=sys.stderr)

    argparser = argparse.ArgumentParser()
    argparser.add_argument("--owner", type=str, required=False,
                           help="GitHub repo owner/org (for the --skip-unchanged feature)")
    argparser.add_argument("--repo", type=str, required=False,
                           help="GitHub repo name (for the --skip-unchanged feature)")
    argparser.add_argument("--pr-number", type=int, required=False,
                           help="PR number under owner/repo (for the --skip-unchanged feature)")
    argparser.add_argument("--skip-unchanged", type=bool, required=False, default=False,
                           action=argparse.BooleanOptionalAction)
    args = argparser.parse_args()

    # https://www.gnu.org/software/make/manual/make.html#Reading-Makefiles
    with open("Makefile", "rt") as makefile:
        lines = read_makefile_lines(makefile)
    tree = extract_target_dependencies(lines)

    write_github_workflow_file(tree, project_dir / ".github" / "workflows" / "build-notebooks.yaml")

    leafs = compute_leafs_in_dependency_tree(tree)
    if args.skip_unchanged:
        logging.info(f"Skipping targets not modified in PR #{args.pr_number}")
        changed_files = gha_pr_changed_files.list_changed_files(args.owner, args.repo, args.pr_number)
        leafs = gha_pr_changed_files.filter_out_unchanged(leafs, changed_files)
    output = print_github_actions_pr_matrix(tree, leafs)

    print("leafs", leafs)
    print(*output, sep="\n")
    with open(os.environ["GITHUB_OUTPUT"], "at") as f:
        for line in output:
            print(line, file=f)


if __name__ == '__main__':
    main()


class SelfTests(unittest.TestCase):
    def test_select_changed_targets(self):
        with open(project_dir / "Makefile", "rt") as makefile:
            lines = read_makefile_lines(makefile)
        tree = extract_target_dependencies(lines)
        leafs = compute_leafs_in_dependency_tree(tree)

        changed_files = ["jupyter/datascience/ubi9-python-3.9/Dockerfile"]

        leafs = gha_pr_changed_files.filter_out_unchanged(leafs, changed_files)
        assert set(leafs) == {'cuda-jupyter-tensorflow-ubi9-python-3.9',
                              'jupyter-trustyai-ubi9-python-3.9',
                              'jupyter-pytorch-ubi9-python-3.9'}
